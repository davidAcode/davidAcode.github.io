{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scratch pad draft 03122019 to free up main colab for Adam.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidAcode/davidAcode.github.io/blob/master/Scratch_pad_draft_03122019_to_free_up_main_colab_for_Adam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "jzQNRfz9FQtU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gtPaIGxGFSFm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Dave, don't forget to insert the \"targeted ad\" analogy at beginning of the Feb 14 colab.\n",
        "#Draft: The Big Picture on Back Prop\n",
        "Let's bust two myths, shall we?  \n",
        "Myth #1: Back Propagation is Super-Hard\n",
        "\n",
        "False.  Back propagation requires patience and persistence.  If you read a text on back prop once and throw up your hands because you understand nothing, you're done.  But if you watch Grant Sanderson's [video 3 on back prop](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) 5 times at reduced speed, then watch [video 4 on the math of back prop](https://www.youtube.com/watch?v=tIeHLnjs5U8&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&t=320s&index=5) five times, you'll be well on your way.  Grit.\n",
        "\n",
        "Myth #2: To Understand Back Prop, You Need Calculus\n",
        "\n",
        "There are many online posts which state with great authority that you need multivariable calculus in order to understand AI.  Not true.  Deep Learning author and guru [Andrew Trask](https://www.cs.ox.ac.uk/people/andrew.trask/) says that, even if you took three semesters of college-level calc, only a tiny subset of that material would be useful for learning back propagation: the Chain Rule.  But, even if you took those 3 semesters of college calculus, the chain rule is often presented very differently in college from the way you would use it in back propagation.  So, bottom line?  Don't make the same mistake I did: I panicked every time I saw the word, \"derivative,\" and it was self-defeating.  You must fight that inner voice saying, \"I don't have the background to master this.\"  There are workarounds--simple ways to do calculus without calling it \"calculus.\"  But there is no workaround for grit.  \n",
        "\n",
        "Here is my favorite saying: \"There is the task, and there is the drama ***about*** the task.\"  \n",
        "Leave your drama here now.  Please give me your grit, and your trust.  Let's learn back prop.\n",
        "\n",
        "Here is the big picture.  What is the purpose of back prop?  To find the best set of adjustments with which to tweak our network so that it gives a better prediction in the next iteration.  Let's break that down:\n",
        "\n",
        "We have control over 16 variables in our network: 12 variables in the 3x4 matrix syn0, and 4 variables in the 4x1 vector syn1.  Look at this diagram and understand that every line (aka, \"edge\" or synapse) you see represents one variable, containing one number, aka one weight.  \n",
        "![alt text](https://lh3.googleusercontent.com/Xo38Db_mZRpNGXbtVCF1qtJEottBhoN2TzvQwJbGUWPuXjoi3SYAVQAvW7xCVaRguJapbcwJvGQ-OvZTxsoTz9mIaGDgTlYhAE_c7WbUGRLTeKxrxAEtfSwZ0M4lbzap6ViWyTCQCWCJET5Vcl0bjWBdr6WSq1k_I_aqTl2vwN3vCpif5Y-Ew8DXltcYZYR6cx4eoOW9qHLi88E9S5KpNxQeFYqXnyh5XQVDKFj-NV4Lr55cGaZnC-BcBvYWI8hdA0UNz1rv_f0FBWBgiDkIgqmPg1O54dVxt_KP25qs9eFnWTHC7QaJEbGf5ekVMGtf3sqj_imlvO7inyOFOnP2Zqh8bbJpGLT8VO9kdvxBPGk8fS8KF5pa_TGUtR_XeD1z1Sq9u8mu4vd_Vvs3YNsNQVVaBj_lP0PqZ2xQ7usWSjoxmpBnNtSeTS_JMMeUSFPPQGpNtq6uxZp-ak8JE6ivpPGZhL7QKZOeQcp0lBL_BylUumqoa718v8Qm2jCCFOawLb4k6-OtwDv8OLFw4b3vzDvoviBd3_1QDKADFaBJcdgXeqVk3TFqHRmLBcnOaP9mmTO5qKZa_Cu5FwNzi-5HwcKa50BX8xQrWpzt-8pibDLOoY54wlETSkE1LCFBcyd6oIiJhZ6FkB0rcWa8NzTv-sLM2NY4GMFx=w970-h588-no\n",
        ")\n",
        "These 16 weights are all we can control.  l0, our input, is fixed and unchanging.  l1 is determined *exclusively* by the weights in syn0 by which you multiply the fixed values of l0.  And l2 is determined *exclusively* by the weights in syn1 by which you multiplied l1.  Those 16 lines pictured above, the synapses, the weights, are the only numbers you can tweak to achieve your goal, which is an l2_error that gets smaller and smaller until l2 almost equals y (in other words, the l2_error ball has come to rest at the bottom of the bowl and your gradient descent is complete).  l2_error is what we call your \"cost,\" and back propagation is the tool that we use to figure out how to tweak the network to reduce the cost as much as possible, as quickly as possible.\n",
        "\n",
        "So, here's the challenge: every time you tweak one of your 16 lines/weights/variables in syn0 and syn1, it has a ripple effect through the network.  How can you calculate the best value for each of the 16 weights while taking into consideration its ripple effect on all the other 15 weights, all at the same time?  That sounds crazy-complex, right?\n",
        "\n",
        "Can do.  Let me show you the World's Greatest Parlor Trick.  Those of you who know calculus will understand when I say we are going to use the Chain Rule to take derivatives.  But those of us who don't know calculus are not intimidated in the least because we will use slope, Good Ol' rise-over-run, to juggle 16 bowling pins in the air at the same time.  The secret?  In this context, to find the slope is to take the derivative.  They are exactly the same thing.\n",
        "\n",
        "\n",
        "##Back Propagation and The Ripple Effect\n",
        "Let's make a Big Picture comparison between Feed Forward and Back Prop.  \n",
        "\n",
        "Here is our overall question: \"When we nudge syn0,1 up or down, how much does that increase or decrease the l2_error?\"  In other words, think of a derivative as a \"sensitivity,\" or a relationship, or a ratio: we know that if we wiggle syn0,1, up or down, then the l2_error will wiggle up or down in proportion to that nudge.  But will it move a little?  A lot?  What is the ratio of l2_error's wiggle to syn0,1's wiggle?  How sensitive is l2_error with respect to syn0,1?\n",
        "\n",
        "Remember: the goal of back prop is to figure out the amount to tweak each of our 16 weights so that we can reduce our l2_error as much as possible in the next iteration.  But the challenge is that each of these 16 weights affects many of the other 15 weights, so you might say that how much you adjust Weight 1 *depends on* how much you adjust Weight 2, which *depends on* how much you adjust Weight 3, and so on.  Keep this *\"depends on\"* image in your mind because it will come in handy later in the math.  As an analogy, imagine 16 of the Minions from the *\"Despicable Me\"* movie, and these 16 minions are aligned in perfect formation and cooperating perfectly as one body in order to serve their master, Felonius Gru.\n",
        "\n",
        "OK.  In our example, we know that our key question is, \"How much do I adjust syn0,1 so that syn0,1 working in synch with its other 15 minions, minimizes l2_error so I can arrive at Castle y and fall into the arms of my princess?\"  \n",
        "\n",
        "The answer to that question is kind of like The Butterfly Effect, where the butterfly flapping its wings in New Mexico sets off a chain of events that results in a hurriance in China.  (Did you notice?  \"chain of events\" sounds a tad like \"chain rule\" in calculus, no?  Oh Dave, so very clever...).  Let's look at a picture of how this analogy might apply to the series of ratios we must calculate in back propagation (errata: delete \"heavy winds off West coast\" because syn1 does not change):\n",
        "\n",
        "[[[insert diagram \"The Butterfly Effect\"]]]\n",
        "Now, let's walk through the math of our butterfly analogy:  When we increase or decrease the value syn0,1, that's like the butterfly in New Mexico flapping its wings.  For simplicty's sake, let's say our original syn0,1 was 1.  We will now tweak it.  We will increase syn0,1 from 1 to 2.  This increase will now ripple through our chain of events.  \n",
        "\n",
        "Ripple 1, the first ripple effect of our tweak to syn0,1 will cause l1_LH to increase by a certain proportion, aka ratio.  That's the \"gust of wind in Nevada.\"\n",
        "\n",
        "Since l1_LH is the input of our sigmoid function, to calculate that ratio of change between l1_LH and L1 (aka, \"to take the slope\") is to measure Ripple 2, the \"heavy winds in L.A.\"  \n",
        "\n",
        "Then, l2_LH will obviously be affected in proportion to the change in l1 and its subsequent multiplication by syn1,1 (which does not change), so measuring that ratio of change will give us Ripple 3, the \"thunderstorm in Hawaii.\"  \n",
        "\n",
        "You can probably guess l2 will change in proportion to the change in l2_LH, so taking the slope of those 2 numbers will give us Ripple 4, the \"storm over the Pacific.\"\n",
        "\n",
        "Finally, when this new l2 is subtracted from our target y value, the remainder, which is l2_error will change, and this is Ripple Effect #5, the \"hurricane in China.\"  \n",
        "\n",
        "Our goal is to calculate the ratio by which each ripple ripples, in order to know the amount we want to increase/decrease syn0,1 in order to minimize l2_error on our next iteration.  When we say our neural network \"learns,\" we really mean it reduces l2_error with each iteration such that the network's predictions become more and more accurate each time.  So, tweaking syn0,1 is like tweaking the flap of the butterfly's wings, which ripples through a chain of events right up to the hurricane in China, which in our example is the reduction of l2_error. \n",
        "\n",
        "Since we're working backwards, we would say, \"How much the hurricance l2_error changes *depends on* how much l2_RH changes, which *depends on* how much l2_LH changes, which *depends on* how much l1_RH changes (we're leaving syn1,1 and the other 14 weights unchanged for now, to simplify our example), which depends on how much l1_LH changes, which depends on how much our butterfly, syn0,1 changes.  Let's have a clean, simple look at that in this diagram:\n",
        "[[[insert diagram beginning with \"line 57:\" the 5 ratios needed to calculate d l2_error/d syn0,1 error]]]\n",
        "\n",
        "\n",
        "So you can see that there is a chain of 5 ratios we need to calculate and multiply together in order to find the ultimate ratio of how much a change in our butterfly, syn0,1 creates the change we want in our hurricane, the l2_error.  How do we calculate those ratios?\n",
        "\n",
        "Don't make the same mistake I did: at first, I thought calculating these ratios was as simple as plugging in a single value for each variable, and that would give me accurate ratios--something silly like this (mistaken!) diagram:\n",
        "[[[insert \"mistaken ratio calc,\" showing no CHANGE ratios]]]\n",
        "\n",
        "For $250,000 cash and a trip to our bonus round, **What's wrong with the above picture?**\n",
        "\n",
        "**DCQ: Is this paragraph as clear as possible?  I'm not perfectly clear on why we need the current and the nearby values of each X and Y variable in order to predict (change???) the future value of the variables.**  All the above math does is to calculate how the *current* syn0,1 weight affects the *current* l2_error! **(AK: This sentence makes no sense.  You described change in the previous paragraph)**  But that's not what we need; we want to predict (change?) the future!  We want to know how much a *change* syn0,1 will ripple through out network to cause a *change* for the better in our next, future iteration of l2_error.  In other words, we're not just comparing how a single number 2 in syn0,1 affects a single number 0.3 in l2_error.  We want to compare how a *change* in the number 2 in syn0,1 will in turn change the 5 rippling ratios to ultimately create a better, future l2_error.  Specifically, we want to make that 0.3 value smaller, as quickly as possible.  So, we don't want a bunch of ratios of numbers; we want the ratio of **CHANGE** in the numbers, the numbers that change our future.  The delta.  \n",
        "\n",
        "**AK: The rest of this seems fine**\n",
        "\n",
        "How do we find ratio of change?  How do we calculate how much a change in the 2 of syn0,1 creates a change in the 0.7 of l2_error?  What we are actually asking here is, What is the change over time?  For simplicity's sake, let's assume that the amount of time that passes between our current l2 prediction and the future l2 prediction of the next iteration is  **DCQ: I'm unclear on how to explain this...**\n",
        "\n",
        "**AK: Including time here is only going to make things worse.  You need a different mechanism. We can discuss tomorrow**\n",
        "\n",
        "We need *two* values for each of our variables.  We already have a current value for each variable.  We need to provide a *second* value for each variable and subtract one value from the other.  The remainder = an \"amount of change,\" or delta, that we can then compare to the amounts of change, or deltas, of the other variables.  It looks like this formula in the top part (ignore the math below for now):\n",
        "[[[insert d y / d x nearby current diagram]]]\n",
        "\n",
        "\"current\" above refers to the current values we have for each variable.  \"nearby\" means we want to provide a number pretty close to our current number, for convenience's sake.  That way, when we subtract the current number from the nearby number, it will yield a small number that's easy to calculate in our ratio of change.  Let's walk through our 5 ratios together so we can practice finding the \"nearby's\" for each ratio.  Once we've done a full example, you'll be a giant step closer to understanding back propagation.\n",
        "\n",
        "OK.  Ratio 1, which is Ripple 5 **(DCQ: correct?)  AK: I would adopt a convention where the ratio number and ripple number are the same.**.  d l2_error / d l2.  Where did our \"currents\" and our \"nearby's\" come from?  Well, x_current is the l2 we caculated from our forward feed, 0.7.  y_current is y-l2 = 1-0.7 = 0.3, our l2_error.  x_nearby is simply a convenient example we made up.  We know that if l2 were 0.9 which is indeed nearby our x_current of 0.7, then y-0.9 would be 0.1.  Hence, x_nearby = 0.9 and y_nearby = 0.1  Once you are clear on your 4 variables, the math is easy and the slope, aka the sensitivity = -1.  This means that for every 1 you increase l2, it decreases the l2_error by -1.    A delta of 1 in our l2 produces a delta of -1 in our l2_error.  Nice.\n",
        "\n",
        "Ratio 2, which is Ripple 4.  d l2_LH / d l2.  We know x_current is l2_LH from our forward feed: 0.94.  y_current is our l2, 0.72 (I added another decimal place).  But how do we find the nearby's?  We eyeball the S-curve of our sigmoid function in the diagram above, to find a convenient ratio to plug in.  We notice that at 0 on the X axis, Y is 0.5.  Nice, let's use that.  So, our x_nearby becomes 0 and our y_nearby becomes 0.5, and it's all over but the math: answer is 0.23.  \n",
        "\n",
        "Why, you might ask, do we eyeball the S-curve of our sigmoid function?  Look at the code in line 57.  It's not asking us to squish the LH side of l2 into a number between 0 and 1 with the `return 1/(1+np.exp(-x))` portion of our sigmoid code.  Rather, this time it's asking us to take the slope (aka derivative) of l2, by calling the `return x*(1-x)` code with `(deriv==True)`.  So, input is the X axis (i.e., 0, and output is the Y axis i.e., 0.5)\n",
        "\n",
        "Next is Ratio 3, Ripple 3. d l2_LH / d l1.  We know x_current is L1, or 0.98 (If you eyeball the S-curve, you'll notice that 0.98 is the Y coordinate of 5, which was our l1_LH product.  Cool, huh?).   y_current is L2_LH, the product of l1 x syn1,1 *plus* the products of the other neurons multiplied by their synapses (which we conveniently made up as -2) = 0.94.  Note that, on this ratio, the code does not ask us to take the derivative (aka slope).  So for our x_nearby and our y_nearby, we can choose any darn number we please.  Let's keep it simple and choose 1's all around.  Subtract, divide, done.  Hallelujah.\n",
        "\n",
        "Ratio 4, Ripple 2.  Having waded far upriver, we are now nearing the source of our ripples, syn0,1!  Exciting.  Note that the code in line 71 on this one is asking us to take slope, so you know we'll be eyeballing our S-curve again.  x_current is l1_LH, or 5, so look that up on our X axis.  y_current lines up at about 0.98, no?  Done.  Now, since we're taking slope this time, for our x-and-y nearby's we have to find a nice pair of coodinates on our S-curve that make for convenient math.  How 'bout x_nearby as 6?  That would make y_nearby as about 0.99.  Lovely.  Do the math and it's 0.01.  Joy.\n",
        "\n",
        "Final Ratio, #5, Ripple 1.  The source of our mountain stream.  x_current is syn0,1, or 2.  y_current is l1_LH, or 5.  Line 76 of our code is not asking for any slopes/derivatives, so for our nearby's, we can use numbers that are, well...conveniently nearby.  Hence: x_nearby is 1 and y_nearby is 4 and the math happens to work out (again, conveniently) to 1, which is the l0 mentioned in line 76.  \n",
        "\n",
        "**DCQ: but wait: How come I can choose any values I want for x_nearby and y_nearby?  Doesn't some type of \"proportionality\" have to be maintained?  For example, if I choose y_nearby is 7 and x_nearby is 2, then my answer is not the convenient 1 of l0.  What's the rule for choosing the \"nearby\" values here?**\n",
        "\n",
        "\n",
        "**AK:  The only value you get to choose is x_nearby. y_nearby must be computed based on your choice of x_nearby.  The distance between x_current and x_nearby depends on how quickly the slope changes.  For linear functions (look like a straight line on the graph), the distance can be very large and the slope will still be exactly right.  For curvy functions (parabolas, sigmoids, etc) the points should be close together to minimize the effect of curvature on your estimate of the slope.**\n",
        "\n",
        "OK.  We now have our 5 ratios, so let's multiply them together to come up with an answer to our question, \"How much will l2_error increase/decrease, depending on how much I increase/decrease syn0,1?\"  \n",
        "\n",
        "```\n",
        "1 x 0.01 x 3 x 0.23 x -1 = -0.0069 = d l2_error / d syn0,1\n",
        "```\n",
        "In other words, for every 1 I increase syn0,1, l2_error decreases by -0.0069.\n",
        "\n",
        "Now let's walk through what would happen, if I updated syn0 for the next iteration, using line 75 of our code:\n",
        "```\n",
        "syn1 += l1.T.dot(l2_delta) \n",
        "Note that \"+=\" means to add to the existing, so:\n",
        "3 += 0.98x(-0.0069)\n",
        "= 3 + -0.006762\n",
        "= 3 - 0.006762\n",
        "= 2.993238 = our new syn1 to be used in our next iteration!\n",
        "```\n",
        "If you have followed things thus far, then you are well on your way to becoming a Back Propagation Rock Star.  If not yet, hey--reread the above several more times and click on the helpful links of the Super Teachers I have cited above.\n",
        "\n",
        "Here's a question I had when I had arrived at this stage: Why bother taking the slope of l2?  \n",
        "\n",
        "We take the slope of l2 to fix the most mistaken of our 16 weights faster.  How?  Well, you may recall from our discussion of the Sigmoid function (and the S-curve diagram) above that the slope of l2 is the confidence level of l2.  The smallest slope numbers indicate the highest confidence level.  Therefore, multiplying the corresponding values of the l2_error by these small numbers ain't gonna cause a big change in the l2_delta product, which is good.  We don't want to change those weights much, because we're already pretty confident in the job they're doing.  \n",
        "\n",
        "But the l2 prediction numbers that we are *least* confident in have the steepest slope, which yields a larger number.  When we mutliply that larger number by the l2_error then the resulting l2_delta has a bigger number.  When we update syn1 later on, that bigger multiplier is going to mean a bigger product, and therefore a bigger change, or tweak, in that value.  This is as it should be, because we want to take the weights we have the least confidence in and change them the most.  That's where we will get the biggest \"bang for our buck\" when it comes to tweaking the 16 weights of our system.  To summarize, taking the slope of l2 gives us the confidence of each l2 prediction, which allows us to home in on the numbers that most need fixing, and fix them the fastest.\n",
        "\n",
        "The next key step is for you to understand how the computer code is doing the same thing we just did manually with our math equations.  I want to show you how these few lines of code...\n",
        "```\n",
        "l2_delta = l2_error*nonlin(l2,deriv=True)\n",
        "l1_error = l2_delta.dot(syn1.T)\n",
        "l1_delta = l1_error * nonlin(l1,deriv=True)\n",
        "syn1 += l1.T.dot(l2_delta)\n",
        "syn0 += l0.T.dot(l1_delta)\n",
        "```\n",
        "...are doing the same thing as this math equation below.\n",
        "[[[insert diagram \"How the Code Synchs with the Math\" ]]]\n",
        "\n",
        "If you compare the code above to the math in the diagram and they don't look consistent to you, that is only because our original code breaks the back propagation process down into several intermediary steps with several extra, intermediary variables.  If you ignore the intermediary variables l2_delta, l1_error, and l1_delta, suddenly things align very nicely.  Look at the line of code beginning with Greek letter Cap delta syn0,1 and follow the arrows from each piece of code to each ratio.  Makes sense?  Lines up nicely, right?  That, my friend, is back propagation.  It took me about one month of daily study to finally arrive at this insight, so don't feel badly if you haven't nailed it yet.  \n",
        "\n",
        "**DCQ: I gotta admit, I still don't see why l0 has anything to do with our final ratio, d k / d syn0,1.  ??  Here's my best guess as to how this stuff works:**\n",
        "\n",
        "\n",
        "**AK:  If an element of l0 is 0, then the weights in syn0 that get multiplied by that element have no effect on the output.  As such, changing them is pointless.**\n",
        "```\n",
        "d l2_err / d l2 = -1 **(DCQ: but where does -1 come from?  It's not consistent with the other ratios below)  AK:  The target value of l2 is 1.  If l2 increases, then the corresponding error decreases.  Increasing l2 by 0.1 causes the error to change by -0.1.  The ratio of the change in error to the change in l2 is -1.**\n",
        "d l2 / d k2 = slope of l2\n",
        "d k2 / d l1 = weight syn1,1\n",
        "d l1 / d k1 = slope of l1\n",
        "d k / d syn0,1 = l0\n",
        "```\n",
        "**DCQ: I confess that I am reading the above ratios as \"y divided by x\" and it seems to work for me.  Is Dave a bad boy?  What is the distinction between \"this is a ratio, not division\" and \"this can also work as division?\"**\n",
        "\n",
        "**AK: Only distinction is that a ratio is a noun and division is an operation, purely linguistic.  The important thing is to be rigorously consistent in terms of what ratio you are dealing with.  The above is \"change in y divided by change in x\"**\n",
        "\n",
        "**DCQ: Adam, do I need to understand this issue below myself?  Do I need to teach it to my students?**\n",
        "\"**You probably noticed that I did not include an arrow for l2_error.  One thing that bothers me about the problem formulation is that there is no direct expression for the scalar cost to be minimized (note that for the batch update l2_error is a 4x1 vector, not a scalar).  It seems implied that the scalar cost C would be defined as C = 0.5xl2_error.Txl2_error.  This would provide dC/dl2_error = l2_error. **\"\n",
        "\n",
        "**You should undersand it, but I wouldn't recommend going into great detail here.  The big picture is that the cost (or objective or error, different authors use different words) must be a scalar.  Trask kind of handwaved through that because the calculus gets kind of nasty.  You can get the concept using a simpler example (e.g. only 1 training example).\n",
        "\n",
        "#DCQ: Adam, for your convenience I put this new material on gradient descent in this colab so you didn't have to scroll through all the other steps:\n",
        "Have you heard of gradient descent?  Gradient descent is all about direction.  It is often described as, \"a ball dropped in a bowl and rolling in a **back-and-forth direction** until it comes to a rest at the global minimum, the bottom of the bowl.\"  That's what the Sigmoid does for us.  It helps us to find the bottom of the bowl, which minimizes the cost function, which minimizes the error in our predictions. **(AK: This isn't really due to the sigmoid, consider removing)** Think of our 60,000 iterations as the ball rolling in a back-and-forth direction in the bowl until it no longer needs to change direction because it has come to rest at the ideal, perfect bottom of that bowl, where error as at a minimum, and life is good.  Picture it like this:\n",
        "\n",
        "![alt text](https://mail.google.com/mail/u/0?ui=2&ik=e3f869f938&attid=0.2&permmsgid=msg-a:r4352876950048414936&th=1691255aa52a4d54&view=fimg&sz=s0-l75-ft&attbid=ANGjdJ8FdFORGv3w0jn-Bs8GhlKpg2D1XPRzSF6OaNCqE8hchNYMIAymIg-nK1xCdIsQup54rJmkW2l0qttCzg03Hq8PJOv4KX0ae14e2dkswvLMt74Rzdhwt2ZJQBQ&disp=emb&realattid=ii_jsexnu8o2)\n",
        "(taken with gratitude from [Grant Sanderson](https://www.youtube.com/watch?v=IHZwWFHWa-w&t=2s&index=3&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) Ch. 2)\n",
        "\n",
        "Above is a nice, simple picture of the \"rolling ball\" of gradient descent.  Line 61 computes each value of l2 as a slope value.  Of the 3 \"bowls\" pictured in the diagram above, it is clear that the true global minimum is the deepest bowl on the far left.  But, for simplicity's sake, let's pretend that the bowl in the middle is the global minimum.  So, a steep slope downwards to the right (i.e., a negative slope value, as depicted by the green line in the picture) means our ball will roll a lot in the negative direction (i.e., to the right), causing a big, negative adjustment to the corresponding weights of syn1 that will be used in the next iteration to predict l2.  But if, for example, you have a shallow slope downwards to the left, that would mean the prediction value is already accurate and confident, which produces a tiny, positive slope value, so the ball will roll very little to the left (i.e., in a positive direction), thus adjusting by very little the corresponding weight in syn1, so the next iteration's prediction of that value will remain largely unchanged.  This makes sense because the back-and-forth motion of the rolling ball is becoming smaller and smaller before it soon comes to rest at the global minimum, the bottom of the bowl, so there's no need to move much.  It is already close to the ideal.\n",
        "\n",
        "The above 2-dimensional diagram is a tad oversimplified, so here's a more accurate picture of what gradient descent looks like:\n",
        "![alt text](https://lh3.googleusercontent.com/jIup60T65tIKtXg0B-Np6jeNXk4TvQTRgBI1btNRZUZ4yy_ZEyL1bN3RwiSjzKNcbyXQN6z7vdV55NzGFxJfUpZXkyU6HTmrScht0rbk5BXGC6eO79LrZuuVpJdHE4fr4QYwvdbO)\n",
        "(taken with gratitude from [Grant Sanderson](https://www.youtube.com/watch?v=IHZwWFHWa-w&t=2s&index=3&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) Ch. 2)\n",
        "\n",
        "Think of the dotted white line in the diagram as the path our gradient descent ball takes toward \"The Bottom of the Bowl where Accurate Prediction Lives.\"  Each dot of that dotted white line represents a tweak, or update of the weights syn0 and syn1, that will take our ball closer-and-closer to the bottom of the bowl, which is the global minimum error, where our NN's predictions are most accurate.\n",
        "\n",
        "#Tying It All Together with One Picture\n",
        "DCQ: Adam, this is the best image I have found on the Net of the Gradient Descent bowl sitting on the \"table top\" plane of the syn0, syn1 grid with an arrow showing Feed Forward and a tiny arrow showing slope/gradient descent.  But, I don't know how to paste it into the colab yet.  Take a look and LMK if you think it's worth trying: https://docs.google.com/document/d/1_YXtTs4vPh33avOFi5xxTaHEzRWPx2Hmr4ehAxEdVhg/edit?usp=sharing\n",
        "\n",
        "Here is a perfect example of why the best teacher is someone who learned yesterday the material you are learning today.  I only discovered the following insight after a year of studying gradient descent, because all the experts take this point so for-granted that they don't bother mentioning it.  Here is a BIG chance for you to learn from my mistakes, and gain a super-key insight that eluded me for over a year, even though it was right under my nose.  Here goes:\n",
        "\n",
        "Take another look at the red, 3-D \"warped bowl\" in the diagram above.  Think of it as just that, a warped bowl.  Notice that the warped bowl is not drifting in space.  It is sitting on a \"white table top,\" that white grid.  Do you notice that the only place our warped bowl actually touches the plane of our white table top is at the global minimum, i.e., the bottom of the lowest dip in the bowl?  Perfect.  Now you have all the info you need for this stunning insight:\n",
        "\n",
        "The grid of our white table top is the axis of syn0 and syn1!  That means that, for example, every value in syn0 is a point on the X axis of our grid, and every value in syn1 is a point on the Y axis of our grid.  When we do a forward feed through out network, the value we arrive at is simply the height of our \"ball\" from the syn0, syn1 coordinate on that grid.  Once we have the height from the grid cooridinates of the plane below, we know *exactly* where our ball is on the surface of our bowl.  And when we compute gradient descent, it tells us the slope of the surface of the bowl at the exact coordinate of (syn0, syn1, and the value from Forward Feed).  Finding the slope of where our ball is tells us the direction our ball should roll to make the quickest descent to the bottom of the bowl where error is 0 because height is 0 because our ball is touching the syn0, syn1 grid plane.\n",
        "\n",
        "And that's it.  That is the best geometric representation of what a neural network does, in one picture.  Why doesn't EVERYBODY teach it like this?  If you can SEE what a neural network does in 3-D, it makes it SO much easier to understand why we do all these abstract steps in math and in code.\n",
        "\n",
        "DCQ: Adam, where does the slope of the sigmoid S-curve fit into this geometic picture?  Is the slope of the S-curve somehow linked to the (gradient descent) slope of the surface of the bowl where our ball is?\n",
        "\n",
        "**AK: It doesn't fit very directly.  The sigmoid is just a piece of a much larger function that governs the behavior of the error.  It is this large function that you are trying to exploit using gradient descent.**\n",
        "\n",
        "Take your time with the above points and make sure you understand them.  Do you see why the sigmoid function is a thing of beauty?  It takes any random number in one of our matrices and:\n",
        "\n",
        "1) turns it into a statistical probability, \n",
        "\n",
        "2) which is also a confidence level, \n",
        "\n",
        "3) which turns into a big-or-small tweak of our synapses, and \n",
        "\n",
        "4) that tweak is always in the direction of greater confidence and accuracy.  \n",
        "\n",
        "The sigmoid function is the miracle by which mere numbers in this matrix can \"learn.\" A single number, along with its many colleagues in a matrix, can represent probability and confidence, which allows a matrix to \"learn\" by trial-and-error.  That is a thing of beauty, but there is more elegance to come!  As you learn other networks, you will see there are many functions that \"learn\" in even more beautiful ways than the sigmoid we have studied here.\n"
      ]
    }
  ]
}